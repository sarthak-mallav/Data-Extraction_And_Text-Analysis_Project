{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "4436c7c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "16b72406",
   "metadata": {},
   "outputs": [],
   "source": [
    "#pip install nltk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "d59e3fec",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     C:\\Users\\Sarthak\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\Sarthak\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "\n",
    "import os\n",
    "import re\n",
    "\n",
    "import nltk\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.corpus import stopwords\n",
    "nltk.download('punkt')\n",
    "nltk.download('stopwords')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "1f5401e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Data Gathering\n",
    "df = pd.read_excel('Input.xlsx')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "b07675d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "#For Fully Display\n",
    "pd.reset_option(\"display.max_rows\")\n",
    "pd.reset_option(\"display.max_columns\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "4779fa67",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>URL_ID</th>\n",
       "      <th>URL</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>37</td>\n",
       "      <td>https://insights.blackcoffer.com/ai-in-healthc...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>38</td>\n",
       "      <td>https://insights.blackcoffer.com/what-if-the-c...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>39</td>\n",
       "      <td>https://insights.blackcoffer.com/what-jobs-wil...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>40</td>\n",
       "      <td>https://insights.blackcoffer.com/will-machine-...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>41</td>\n",
       "      <td>https://insights.blackcoffer.com/will-ai-repla...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   URL_ID                                                URL\n",
       "0      37  https://insights.blackcoffer.com/ai-in-healthc...\n",
       "1      38  https://insights.blackcoffer.com/what-if-the-c...\n",
       "2      39  https://insights.blackcoffer.com/what-jobs-wil...\n",
       "3      40  https://insights.blackcoffer.com/will-machine-...\n",
       "4      41  https://insights.blackcoffer.com/will-ai-repla..."
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head() #DataFrame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "6ea3e637",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<generator object DataFrame.iterrows at 0x000001C121A5F220>"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.iterrows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "13afc414",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "can't get title of 44\n",
      "can't get title of 57\n",
      "can't get title of 144\n"
     ]
    }
   ],
   "source": [
    "#Iterate row\n",
    "for index, row in df.iterrows():\n",
    "    url = row['URL']\n",
    "    url_id = row['URL_ID']\n",
    "\n",
    "  # make a request to url\n",
    "    header = {'User-Agent': \"Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/108.0.0.0 Safari/537.36\"}\n",
    "    try:\n",
    "        response = requests.get(url,headers=header)\n",
    "    except:\n",
    "        print(\"can't get response of {}\".format(url_id))\n",
    "\n",
    "  #create a beautifulsoup object\n",
    "    try:\n",
    "        soup = BeautifulSoup(response.content, 'html.parser')\n",
    "    except:\n",
    "        print(\"can't get page of {}\".format(url_id))\n",
    "        \n",
    "  #find title\n",
    "    try:\n",
    "        title = soup.find('h1').get_text()\n",
    "    except:\n",
    "        print(\"can't get title of {}\".format(url_id))\n",
    "        continue\n",
    "        \n",
    "  #find text\n",
    "    article = \"\"\n",
    "    try:\n",
    "        for p in soup.find_all('p'):\n",
    "            article += p.get_text()\n",
    "    except:\n",
    "        print(\"can't get text of {}\".format(url_id))\n",
    "\n",
    "    output_directory = r'D:\\DATA SCIENCE\\Internshala Task\\Blackcoffer\\1\\Data_Extraction_and_Text_Analysis_for_Blackcoffer_company.-main\\Project Solve'\n",
    "    file_name = os.path.join(output_directory, f'{url_id}.txt')\n",
    "    with open(file_name, 'w', encoding='utf-8') as file:\n",
    "        file.write(title + '\\n' + article)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "75e42805",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "05978241",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Directories\n",
    "text_dir ='D:\\\\DATA SCIENCE\\\\Internshala Task\\\\Blackcoffer\\\\1\\\\Data_Extraction_and_Text_Analysis_for_Blackcoffer_company.-main\\\\Project Solve\\\\TitleText1'\n",
    "stopwords_dir = 'D:\\\\DATA SCIENCE\\\\Internshala Task\\\\Blackcoffer\\\\1\\\\Data_Extraction_and_Text_Analysis_for_Blackcoffer_company.-main\\\\Project Solve\\\\StopWords'\n",
    "sentment_dir = 'D:\\\\DATA SCIENCE\\\\Internshala Task\\\\Blackcoffer\\\\1\\\\Data_Extraction_and_Text_Analysis_for_Blackcoffer_company.-main\\\\Project Solve\\\\MasterDictionary'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "5dbd9649",
   "metadata": {},
   "outputs": [],
   "source": [
    "# load all stop wors from the stopwords directory and store in the set variable\n",
    "stop_words = set()\n",
    "for files in os.listdir(stopwords_dir):\n",
    "  with open(os.path.join(stopwords_dir,files),'r',encoding='ISO-8859-1') as f:\n",
    "    stop_words.update(set(f.read().splitlines()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "b7f0fd4b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# load all text files  from the  directory and store in a list(docs)\n",
    "docs = []\n",
    "for text_file in os.listdir(text_dir):\n",
    "  with open(os.path.join(text_dir,text_file),'r') as f:\n",
    "    text = f.read()\n",
    "#tokenize the given text file\n",
    "    words = word_tokenize(text)\n",
    "# remove the stop words from the tokens\n",
    "    filtered_text = [word for word in words if word.lower() not in stop_words]\n",
    "# add each filtered tokens of each file into a list\n",
    "    docs.append(filtered_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "4a7e9683",
   "metadata": {},
   "outputs": [],
   "source": [
    "# store positive, Negative words from the directory\n",
    "pos=set()\n",
    "neg=set()\n",
    "\n",
    "for files in os.listdir(sentment_dir):\n",
    "  if files =='positive-words.txt':\n",
    "    with open(os.path.join(sentment_dir,files),'r',encoding='ISO-8859-1') as f:\n",
    "      pos.update(f.read().splitlines())\n",
    "  else:\n",
    "    with open(os.path.join(sentment_dir,files),'r',encoding='ISO-8859-1') as f:\n",
    "      neg.update(f.read().splitlines())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "960cb7f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# now collect the positive  and negative words from each file\n",
    "# calculate the scores from the positive and negative words \n",
    "positive_words = []\n",
    "Negative_words =[]\n",
    "positive_score = []\n",
    "negative_score = []\n",
    "polarity_score = []\n",
    "subjectivity_score = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "2862d189",
   "metadata": {},
   "outputs": [],
   "source": [
    "#iterate through the list of docs\n",
    "for i in range(len(docs)):\n",
    "  positive_words.append([word for word in docs[i] if word.lower() in pos])\n",
    "  Negative_words.append([word for word in docs[i] if word.lower() in neg])\n",
    "  positive_score.append(len(positive_words[i]))\n",
    "  negative_score.append(len(Negative_words[i]))\n",
    "  polarity_score.append((positive_score[i] - negative_score[i]) / ((positive_score[i] + negative_score[i]) + 0.000001))\n",
    "  subjectivity_score.append((positive_score[i] + negative_score[i]) / ((len(docs[i])) + 0.000001))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "ae3e5b70",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\Sarthak\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "import re\n",
    "from nltk.corpus import stopwords\n",
    "\n",
    "# Download the stopwords if you haven't already\n",
    "import nltk\n",
    "nltk.download('stopwords')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "166ebdbb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set up stopwords\n",
    "stopwords = set(stopwords.words('english'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "95487be7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the directory where your text files are located\n",
    "text_dir = 'D:\\\\DATA SCIENCE\\\\Internshala Task\\\\Blackcoffer\\\\1\\\\Data_Extraction_and_Text_Analysis_for_Blackcoffer_company.-main\\\\Project Solve\\\\TitleText1'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "1ae10909",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Lists to store the calculated metrics\n",
    "avg_sentence_length = []\n",
    "Percentage_of_Complex_words = []\n",
    "Fog_Index = []\n",
    "complex_word_count = []\n",
    "avg_syllable_word_count = []\n",
    "\n",
    "def measure(file):\n",
    "    with open(os.path.join(text_dir, file), 'r') as f:\n",
    "        text = f.read()\n",
    "    \n",
    "    # Remove punctuations\n",
    "    text = re.sub(r'[^\\w\\s.]', '', text)\n",
    "    \n",
    "    # Split the given text file into sentences\n",
    "    sentences = text.split('.')\n",
    "    \n",
    "    # Total number of sentences in a file\n",
    "    num_sentences = len(sentences)\n",
    "    \n",
    "    # Total words in the file (excluding stopwords)\n",
    "    words = [word for word in text.split() if word.lower() not in stopwords]\n",
    "    num_words = len(words)\n",
    "    \n",
    "    # Complex words are words in the text that contain more than two syllables.\n",
    "    complex_words = [word for word in words if len(re.findall(r'[aeiouAEIOU]{3,}', word)) > 2]\n",
    "    \n",
    "    # Syllable Count Per Word\n",
    "    syllable_count = sum(len(re.findall(r'[aeiouAEIOU]+', word)) for word in words)\n",
    "    \n",
    "    avg_sentence_len = num_words / num_sentences if num_sentences > 0 else 0\n",
    "    avg_syllable_word_count = syllable_count / len(words) if len(words) > 0 else 0\n",
    "    Percent_Complex_words = len(complex_words) / num_words if num_words > 0 else 0\n",
    "    Fog_Index = 0.4 * (avg_sentence_len + Percent_Complex_words)\n",
    "    \n",
    "    return avg_sentence_len, Percent_Complex_words, Fog_Index, len(complex_words), avg_syllable_word_count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "b3dde945",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Iterate through each file or doc in the specified directory\n",
    "for file in os.listdir(text_dir):\n",
    "    x, y, z, a, b = measure(file)\n",
    "    avg_sentence_length.append(x)\n",
    "    Percentage_of_Complex_words.append(y)\n",
    "    Fog_Index.append(z)\n",
    "    complex_word_count.append(a)\n",
    "    avg_syllable_word_count.append(b)\n",
    "\n",
    "# Now you have lists containing the calculated metrics for each file in the directory\n",
    "# You can use these lists as needed for further analysis or reporting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "fa83cd02",
   "metadata": {},
   "outputs": [],
   "source": [
    "#main\n",
    "# Word Count and Average Word Length Sum of the total number of characters in each word/Total number of words\n",
    "# We count the total cleaned words present in the text by \n",
    "# removing the stop words (using stopwords class of nltk package).\n",
    "# removing any punctuations like ? ! , . from the word before counting.\n",
    "\n",
    "def cleaned_words(file):\n",
    "  with open(os.path.join(text_dir,file), 'r') as f:\n",
    "    text = f.read()\n",
    "    text = re.sub(r'[^\\w\\s]', '' , text)\n",
    "    words = [word  for word in text.split() if word.lower() not in stopwords]\n",
    "    length = sum(len(word) for word in words)\n",
    "    #average_word_length = length / len(words)\n",
    "    average_word_length = length / len(words) if len(words) > 0 else 0\n",
    "\n",
    "  return len(words),average_word_length\n",
    "\n",
    "word_count = []\n",
    "average_word_length = []\n",
    "for file in os.listdir(text_dir):\n",
    "  x, y = cleaned_words(file)\n",
    "  word_count.append(x)\n",
    "  average_word_length.append(y)\n",
    "\n",
    "\n",
    "# To calculate Personal Pronouns mentioned in the text, we use regex to find \n",
    "# the counts of the words - “I,” “we,” “my,” “ours,” and “us”. Special care is taken\n",
    "#  so that the country name US is not included in the list.\n",
    "def count_personal_pronouns(file):\n",
    "  with open(os.path.join(text_dir,file), 'r') as f:\n",
    "    text = f.read()\n",
    "    personal_pronouns = [\"I\", \"we\", \"my\", \"ours\", \"us\"]\n",
    "    count = 0\n",
    "    for pronoun in personal_pronouns:\n",
    "      count += len(re.findall(r\"\\b\" + pronoun + r\"\\b\", text)) # \\b is used to match word boundaries\n",
    "  return count\n",
    "\n",
    "pp_count = []\n",
    "for file in os.listdir(text_dir):\n",
    "  x = count_personal_pronouns(file)\n",
    "  pp_count.append(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "f1092022",
   "metadata": {},
   "outputs": [],
   "source": [
    "output_df = pd.read_excel('Output Data Structure.xlsx')\n",
    "output_df_1 = output_df.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "3f0468ce",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['URL_ID', 'URL', 'POSITIVE SCORE', 'NEGATIVE SCORE', 'POLARITY SCORE',\n",
       "       'SUBJECTIVITY SCORE', 'AVG SENTENCE LENGTH',\n",
       "       'PERCENTAGE OF COMPLEX WORDS', 'FOG INDEX',\n",
       "       'AVG NUMBER OF WORDS PER SENTENCE', 'COMPLEX WORD COUNT', 'WORD COUNT',\n",
       "       'SYLLABLE PER WORD', 'PERSONAL PRONOUNS', 'AVG WORD LENGTH'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "output_df_1.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "87213a95",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>URL_ID</th>\n",
       "      <th>URL</th>\n",
       "      <th>POSITIVE SCORE</th>\n",
       "      <th>NEGATIVE SCORE</th>\n",
       "      <th>POLARITY SCORE</th>\n",
       "      <th>SUBJECTIVITY SCORE</th>\n",
       "      <th>AVG SENTENCE LENGTH</th>\n",
       "      <th>PERCENTAGE OF COMPLEX WORDS</th>\n",
       "      <th>FOG INDEX</th>\n",
       "      <th>AVG NUMBER OF WORDS PER SENTENCE</th>\n",
       "      <th>COMPLEX WORD COUNT</th>\n",
       "      <th>WORD COUNT</th>\n",
       "      <th>SYLLABLE PER WORD</th>\n",
       "      <th>PERSONAL PRONOUNS</th>\n",
       "      <th>AVG WORD LENGTH</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>37</td>\n",
       "      <td>https://insights.blackcoffer.com/ai-in-healthc...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>38</td>\n",
       "      <td>https://insights.blackcoffer.com/what-if-the-c...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>39</td>\n",
       "      <td>https://insights.blackcoffer.com/what-jobs-wil...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>40</td>\n",
       "      <td>https://insights.blackcoffer.com/will-machine-...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>41</td>\n",
       "      <td>https://insights.blackcoffer.com/will-ai-repla...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>109</th>\n",
       "      <td>146</td>\n",
       "      <td>https://insights.blackcoffer.com/blockchain-fo...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>110</th>\n",
       "      <td>147</td>\n",
       "      <td>https://insights.blackcoffer.com/the-future-of...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>111</th>\n",
       "      <td>148</td>\n",
       "      <td>https://insights.blackcoffer.com/big-data-anal...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>112</th>\n",
       "      <td>149</td>\n",
       "      <td>https://insights.blackcoffer.com/business-anal...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>113</th>\n",
       "      <td>150</td>\n",
       "      <td>https://insights.blackcoffer.com/challenges-an...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>114 rows × 15 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     URL_ID                                                URL  \\\n",
       "0        37  https://insights.blackcoffer.com/ai-in-healthc...   \n",
       "1        38  https://insights.blackcoffer.com/what-if-the-c...   \n",
       "2        39  https://insights.blackcoffer.com/what-jobs-wil...   \n",
       "3        40  https://insights.blackcoffer.com/will-machine-...   \n",
       "4        41  https://insights.blackcoffer.com/will-ai-repla...   \n",
       "..      ...                                                ...   \n",
       "109     146  https://insights.blackcoffer.com/blockchain-fo...   \n",
       "110     147  https://insights.blackcoffer.com/the-future-of...   \n",
       "111     148  https://insights.blackcoffer.com/big-data-anal...   \n",
       "112     149  https://insights.blackcoffer.com/business-anal...   \n",
       "113     150  https://insights.blackcoffer.com/challenges-an...   \n",
       "\n",
       "     POSITIVE SCORE  NEGATIVE SCORE  POLARITY SCORE  SUBJECTIVITY SCORE  \\\n",
       "0               NaN             NaN             NaN                 NaN   \n",
       "1               NaN             NaN             NaN                 NaN   \n",
       "2               NaN             NaN             NaN                 NaN   \n",
       "3               NaN             NaN             NaN                 NaN   \n",
       "4               NaN             NaN             NaN                 NaN   \n",
       "..              ...             ...             ...                 ...   \n",
       "109             NaN             NaN             NaN                 NaN   \n",
       "110             NaN             NaN             NaN                 NaN   \n",
       "111             NaN             NaN             NaN                 NaN   \n",
       "112             NaN             NaN             NaN                 NaN   \n",
       "113             NaN             NaN             NaN                 NaN   \n",
       "\n",
       "     AVG SENTENCE LENGTH  PERCENTAGE OF COMPLEX WORDS  FOG INDEX  \\\n",
       "0                    NaN                          NaN        NaN   \n",
       "1                    NaN                          NaN        NaN   \n",
       "2                    NaN                          NaN        NaN   \n",
       "3                    NaN                          NaN        NaN   \n",
       "4                    NaN                          NaN        NaN   \n",
       "..                   ...                          ...        ...   \n",
       "109                  NaN                          NaN        NaN   \n",
       "110                  NaN                          NaN        NaN   \n",
       "111                  NaN                          NaN        NaN   \n",
       "112                  NaN                          NaN        NaN   \n",
       "113                  NaN                          NaN        NaN   \n",
       "\n",
       "     AVG NUMBER OF WORDS PER SENTENCE  COMPLEX WORD COUNT  WORD COUNT  \\\n",
       "0                                 NaN                 NaN         NaN   \n",
       "1                                 NaN                 NaN         NaN   \n",
       "2                                 NaN                 NaN         NaN   \n",
       "3                                 NaN                 NaN         NaN   \n",
       "4                                 NaN                 NaN         NaN   \n",
       "..                                ...                 ...         ...   \n",
       "109                               NaN                 NaN         NaN   \n",
       "110                               NaN                 NaN         NaN   \n",
       "111                               NaN                 NaN         NaN   \n",
       "112                               NaN                 NaN         NaN   \n",
       "113                               NaN                 NaN         NaN   \n",
       "\n",
       "     SYLLABLE PER WORD  PERSONAL PRONOUNS  AVG WORD LENGTH  \n",
       "0                  NaN                NaN              NaN  \n",
       "1                  NaN                NaN              NaN  \n",
       "2                  NaN                NaN              NaN  \n",
       "3                  NaN                NaN              NaN  \n",
       "4                  NaN                NaN              NaN  \n",
       "..                 ...                ...              ...  \n",
       "109                NaN                NaN              NaN  \n",
       "110                NaN                NaN              NaN  \n",
       "111                NaN                NaN              NaN  \n",
       "112                NaN                NaN              NaN  \n",
       "113                NaN                NaN              NaN  \n",
       "\n",
       "[114 rows x 15 columns]"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "output_df_1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "cccd1771",
   "metadata": {},
   "outputs": [],
   "source": [
    "output_df1 = pd.read_excel('Output Data Structure.xlsx')\n",
    "output_df1 = output_df_1.drop(['URL_ID', 'URL'],axis=1,inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "bd477ddc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>POSITIVE SCORE</th>\n",
       "      <th>NEGATIVE SCORE</th>\n",
       "      <th>POLARITY SCORE</th>\n",
       "      <th>SUBJECTIVITY SCORE</th>\n",
       "      <th>AVG SENTENCE LENGTH</th>\n",
       "      <th>PERCENTAGE OF COMPLEX WORDS</th>\n",
       "      <th>FOG INDEX</th>\n",
       "      <th>AVG NUMBER OF WORDS PER SENTENCE</th>\n",
       "      <th>COMPLEX WORD COUNT</th>\n",
       "      <th>WORD COUNT</th>\n",
       "      <th>SYLLABLE PER WORD</th>\n",
       "      <th>PERSONAL PRONOUNS</th>\n",
       "      <th>AVG WORD LENGTH</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>109</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>110</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>111</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>112</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>113</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>114 rows × 13 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     POSITIVE SCORE  NEGATIVE SCORE  POLARITY SCORE  SUBJECTIVITY SCORE  \\\n",
       "0               NaN             NaN             NaN                 NaN   \n",
       "1               NaN             NaN             NaN                 NaN   \n",
       "2               NaN             NaN             NaN                 NaN   \n",
       "3               NaN             NaN             NaN                 NaN   \n",
       "4               NaN             NaN             NaN                 NaN   \n",
       "..              ...             ...             ...                 ...   \n",
       "109             NaN             NaN             NaN                 NaN   \n",
       "110             NaN             NaN             NaN                 NaN   \n",
       "111             NaN             NaN             NaN                 NaN   \n",
       "112             NaN             NaN             NaN                 NaN   \n",
       "113             NaN             NaN             NaN                 NaN   \n",
       "\n",
       "     AVG SENTENCE LENGTH  PERCENTAGE OF COMPLEX WORDS  FOG INDEX  \\\n",
       "0                    NaN                          NaN        NaN   \n",
       "1                    NaN                          NaN        NaN   \n",
       "2                    NaN                          NaN        NaN   \n",
       "3                    NaN                          NaN        NaN   \n",
       "4                    NaN                          NaN        NaN   \n",
       "..                   ...                          ...        ...   \n",
       "109                  NaN                          NaN        NaN   \n",
       "110                  NaN                          NaN        NaN   \n",
       "111                  NaN                          NaN        NaN   \n",
       "112                  NaN                          NaN        NaN   \n",
       "113                  NaN                          NaN        NaN   \n",
       "\n",
       "     AVG NUMBER OF WORDS PER SENTENCE  COMPLEX WORD COUNT  WORD COUNT  \\\n",
       "0                                 NaN                 NaN         NaN   \n",
       "1                                 NaN                 NaN         NaN   \n",
       "2                                 NaN                 NaN         NaN   \n",
       "3                                 NaN                 NaN         NaN   \n",
       "4                                 NaN                 NaN         NaN   \n",
       "..                                ...                 ...         ...   \n",
       "109                               NaN                 NaN         NaN   \n",
       "110                               NaN                 NaN         NaN   \n",
       "111                               NaN                 NaN         NaN   \n",
       "112                               NaN                 NaN         NaN   \n",
       "113                               NaN                 NaN         NaN   \n",
       "\n",
       "     SYLLABLE PER WORD  PERSONAL PRONOUNS  AVG WORD LENGTH  \n",
       "0                  NaN                NaN              NaN  \n",
       "1                  NaN                NaN              NaN  \n",
       "2                  NaN                NaN              NaN  \n",
       "3                  NaN                NaN              NaN  \n",
       "4                  NaN                NaN              NaN  \n",
       "..                 ...                ...              ...  \n",
       "109                NaN                NaN              NaN  \n",
       "110                NaN                NaN              NaN  \n",
       "111                NaN                NaN              NaN  \n",
       "112                NaN                NaN              NaN  \n",
       "113                NaN                NaN              NaN  \n",
       "\n",
       "[114 rows x 13 columns]"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "output_df_1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "80731162",
   "metadata": {},
   "outputs": [],
   "source": [
    "output_df_1 = pd.read_excel('Output Data Structure.xlsx')\n",
    "# URL_ID 44 ,57, 144 does not exists i,e. page does not exist, throughs 404 error\n",
    "# so we are going to drop these rows from the table\n",
    "output_df_1.drop([44-37,57-37,144-37], axis = 0, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "eb350ecd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# These are the required parameters \n",
    "variables = [positive_score,\n",
    "            negative_score,\n",
    "            polarity_score,\n",
    "            subjectivity_score,\n",
    "            avg_sentence_length,\n",
    "            Percentage_of_Complex_words,\n",
    "            Fog_Index,\n",
    "            avg_sentence_length,\n",
    "            complex_word_count,\n",
    "            word_count,\n",
    "            avg_syllable_word_count,\n",
    "            pp_count,\n",
    "            average_word_length]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "6b13bc07",
   "metadata": {},
   "outputs": [],
   "source": [
    "# write the values to the dataframe\n",
    "if len(output_df_1.columns) == len(variables):\n",
    "    for i, var in enumerate(variables):\n",
    "        output_df_1.iloc[:, i + 2] = var"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "d2c992a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "#now save the dataframe to the disk\n",
    "output_df_1.to_csv('Output_Data.csv')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
